{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3276dbae16734a6380a5ec5139dcf62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117e644f73e144e283264e1718719b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BartModel(\n",
       "  (shared): Embedding(50265, 768, padding_idx=1)\n",
       "  (encoder): BartEncoder(\n",
       "    (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "    (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x BartEncoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation_fn): GELUActivation()\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): BartDecoder(\n",
       "    (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "    (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x BartDecoderLayer(\n",
       "        (self_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "import accelerate\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = transformers.AutoModel.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "# Create an Accelerate Accelerator\n",
    "accelerator = accelerate.Accelerator()\n",
    "\n",
    "# Move the model to the GPU\n",
    "model.to(accelerator.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def load_dataset(csv_file):\n",
    "    \"\"\"Loads a code migration dataset from a CSV file.\n",
    "\n",
    "    Args:\n",
    "        csv_file: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples, where each tuple contains the input and output code snippets.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = []\n",
    "    with open(csv_file, \"r\") as f:\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "        for row in reader:\n",
    "            input_code = row[0]\n",
    "            output_code = row[1]\n",
    "\n",
    "            dataset.append((input_code, output_code))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Load the modified dataset\n",
    "dataset = load_dataset(\"Data\\code_to_code_geekforgeek.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "def create_train_dataloader(dataset, batch_size):\n",
    "    \"\"\"Creates a training dataloader for a code migration dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset: A list of tuples, where each tuple contains the input and output code snippets.\n",
    "        batch_size: The batch size.\n",
    "\n",
    "    Returns:\n",
    "        A DataLoader object.\n",
    "    \"\"\"\n",
    "\n",
    "    train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_dataloader\n",
    "\n",
    "# Create the training dataloader\n",
    "train_dataloader = create_train_dataloader(dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "num_training_steps = len(train_dataloader) * 2000\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=1000, num_training_steps=num_training_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\Langchain\\Code Migration\\FineTuning.ipynb Cell 7\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Langchain/Code%20Migration/FineTuning.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2000\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Langchain/Code%20Migration/FineTuning.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Langchain/Code%20Migration/FineTuning.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39m# Convert the list of code snippets to tensors\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Langchain/Code%20Migration/FineTuning.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         batch \u001b[39m=\u001b[39m tokenizer(batch, return_tensors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Langchain/Code%20Migration/FineTuning.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39m# Move the batch to the GPU\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Langchain/Code%20Migration/FineTuning.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mto(accelerator\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2790\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2788\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2789\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2790\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_one(text\u001b[39m=\u001b[39mtext, text_pair\u001b[39m=\u001b[39mtext_pair, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mall_kwargs)\n\u001b[0;32m   2791\u001b[0m \u001b[39mif\u001b[39;00m text_target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2792\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[1;32mc:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2876\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2871\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2872\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch length of `text`: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text)\u001b[39m}\u001b[39;00m\u001b[39m does not match batch length of `text_pair`:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2873\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text_pair)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2874\u001b[0m         )\n\u001b[0;32m   2875\u001b[0m     batch_text_or_text_pairs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(text, text_pair)) \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m text\n\u001b[1;32m-> 2876\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_encode_plus(\n\u001b[0;32m   2877\u001b[0m         batch_text_or_text_pairs\u001b[39m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   2878\u001b[0m         add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2879\u001b[0m         padding\u001b[39m=\u001b[39mpadding,\n\u001b[0;32m   2880\u001b[0m         truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   2881\u001b[0m         max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[0;32m   2882\u001b[0m         stride\u001b[39m=\u001b[39mstride,\n\u001b[0;32m   2883\u001b[0m         is_split_into_words\u001b[39m=\u001b[39mis_split_into_words,\n\u001b[0;32m   2884\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   2885\u001b[0m         return_tensors\u001b[39m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2886\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   2887\u001b[0m         return_attention_mask\u001b[39m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   2888\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   2889\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   2890\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   2891\u001b[0m         return_length\u001b[39m=\u001b[39mreturn_length,\n\u001b[0;32m   2892\u001b[0m         verbose\u001b[39m=\u001b[39mverbose,\n\u001b[0;32m   2893\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2894\u001b[0m     )\n\u001b[0;32m   2895\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2896\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_plus(\n\u001b[0;32m   2897\u001b[0m         text\u001b[39m=\u001b[39mtext,\n\u001b[0;32m   2898\u001b[0m         text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2914\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2915\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3067\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   3057\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   3058\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   3059\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[0;32m   3060\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3064\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   3065\u001b[0m )\n\u001b[1;32m-> 3067\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_encode_plus(\n\u001b[0;32m   3068\u001b[0m     batch_text_or_text_pairs\u001b[39m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   3069\u001b[0m     add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[0;32m   3070\u001b[0m     padding_strategy\u001b[39m=\u001b[39mpadding_strategy,\n\u001b[0;32m   3071\u001b[0m     truncation_strategy\u001b[39m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   3072\u001b[0m     max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[0;32m   3073\u001b[0m     stride\u001b[39m=\u001b[39mstride,\n\u001b[0;32m   3074\u001b[0m     is_split_into_words\u001b[39m=\u001b[39mis_split_into_words,\n\u001b[0;32m   3075\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   3076\u001b[0m     return_tensors\u001b[39m=\u001b[39mreturn_tensors,\n\u001b[0;32m   3077\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   3078\u001b[0m     return_attention_mask\u001b[39m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   3079\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   3080\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   3081\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   3082\u001b[0m     return_length\u001b[39m=\u001b[39mreturn_length,\n\u001b[0;32m   3083\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[0;32m   3084\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   3085\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bart\\tokenization_bart_fast.py:267\u001b[0m, in \u001b[0;36mBartTokenizerFast._batch_encode_plus\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[39mif\u001b[39;00m is_split_into_words \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_prefix_space:\n\u001b[0;32m    262\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    263\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou need to instantiate \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m with add_prefix_space=True \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    264\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto use it with pretokenized inputs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    265\u001b[0m     )\n\u001b[1;32m--> 267\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_batch_encode_plus(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:504\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39m# Set the truncation and padding strategy and restore the initial configuration\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_truncation_and_padding(\n\u001b[0;32m    497\u001b[0m     padding_strategy\u001b[39m=\u001b[39mpadding_strategy,\n\u001b[0;32m    498\u001b[0m     truncation_strategy\u001b[39m=\u001b[39mtruncation_strategy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    501\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    502\u001b[0m )\n\u001b[1;32m--> 504\u001b[0m encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tokenizer\u001b[39m.\u001b[39;49mencode_batch(\n\u001b[0;32m    505\u001b[0m     batch_text_or_text_pairs,\n\u001b[0;32m    506\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[0;32m    507\u001b[0m     is_pretokenized\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[0;32m    508\u001b[0m )\n\u001b[0;32m    510\u001b[0m \u001b[39m# Convert encoding to dict\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[39m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \u001b[39m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \u001b[39m#                       List[EncodingFast]\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[39m#                    ]\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[39m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[0;32m    516\u001b[0m tokens_and_encodings \u001b[39m=\u001b[39m [\n\u001b[0;32m    517\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_encoding(\n\u001b[0;32m    518\u001b[0m         encoding\u001b[39m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[39mfor\u001b[39;00m encoding \u001b[39min\u001b[39;00m encodings\n\u001b[0;32m    528\u001b[0m ]\n",
      "\u001b[1;31mTypeError\u001b[0m: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "for epoch in range(2000):\n",
    "    for batch in train_dataloader:\n",
    "        # Convert the list of code snippets to tensors\n",
    "        batch = tokenizer(batch, return_tensors=\"pt\")\n",
    "        # Move the batch to the GPU\n",
    "        batch = batch.to(accelerator.device)\n",
    "        print(\"To forward pass\")\n",
    "        # Forward pass\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        # Loss\n",
    "        print(\"To loss\")\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass\n",
    "        print(\"To backward pass\")\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate\n",
    "        print(\"Updating learning rate\")\n",
    "        scheduler.step()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"fine-tuned-bart-base-code-migration\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
