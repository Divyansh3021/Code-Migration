{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import accelerate\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = transformers.AutoModel.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "# Create an Accelerate Accelerator\n",
    "accelerator = accelerate.Accelerator()\n",
    "\n",
    "# Move the model to the GPU\n",
    "model.to(accelerator.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def load_dataset(csv_file):\n",
    "    \"\"\"Loads a code migration dataset from a CSV file.\n",
    "\n",
    "    Args:\n",
    "        csv_file: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples, where each tuple contains the input and output code snippets.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = []\n",
    "    with open(csv_file, \"r\") as f:\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "        for row in reader:\n",
    "            input_code = row[0]\n",
    "            output_code = row[1]\n",
    "\n",
    "            dataset.append((input_code, output_code))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Load the modified dataset\n",
    "dataset = load_dataset(\"Data\\code_to_code_geekforgeek.csv\")\n",
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7121\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "def create_train_dataloader(dataset, batch_size):\n",
    "    \"\"\"Creates a training dataloader for a code migration dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset: A list of tuples, where each tuple contains the input and output code snippets.\n",
    "        batch_size: The batch size.\n",
    "\n",
    "    Returns:\n",
    "        A DataLoader object.\n",
    "    \"\"\"\n",
    "\n",
    "    train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_dataloader\n",
    "\n",
    "# Create the training dataloader\n",
    "train_dataloader = create_train_dataloader(dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "num_training_steps = len(train_dataloader) * 2000\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=1000, num_training_steps=num_training_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Translate Java to C++: \\nimport java.util. *;\\nimport java.util.stream.*;\\nimport java.lang.*;\\nimport javafx.util.Pair;\\npublic class C_PROGRAM_CONCATENATE_STRING_GIVEN_NUMBER_TIMES{\\nstatic String f_gold ( String s , int n ) {\\n  String s1 = s ;\\n  for ( int i = 1 ;\\n  i < n ;\\n  i ++ ) s += s1 ;\\n  return s ;\\n}\\n\\n\\n', 'Translate Python to C++: \\nif __name__ == \\'__main__\\':\\n    param = [\\n    (2009.019461888707,),\\n    (-1480.5131394215787,),\\n    (357.7870347569567,),\\n    (-8040.293697508038,),\\n    (3821.882657293133,),\\n    (-6840.635072240347,),\\n    (1623.036598830132,),\\n    (-9714.00706195298,),\\n    (3916.454769669618,),\\n    (-669.068424712943,)\\n        ]\\n    n_success = 0\\n    for i, parameters_set in enumerate(param):\\n        if abs(1 - (0.0000001 + abs(f_gold(*parameters_set))) / (abs(f_filled(*parameters_set)) + 0.0000001)) < 0.001:\\n            n_success+=1\\n    print(\"#Results: %i, %i\" % (n_success, len(param)))', 'Translate C++ to Python: \\nusing namespace std;\\nint f_gold ( int n ) {\\n  if ( n < 3 ) return n;\\n  if ( n >= 3 && n < 10 ) return n - 1;\\n  int po = 1;\\n  while ( n / po > 9 ) po = po * 10;\\n  int msd = n / po;\\n  if ( msd != 3 ) return f_gold ( msd ) * f_gold ( po - 1 ) + f_gold ( msd ) + f_gold ( n % po );\\n  else return f_gold ( msd * po - 1 );\\n}\\n\\n\\n', 'Translate C++ to Python: \\nint main() {\\n    int n_success = 0;\\n    vector<int> param0 {19,23,92,9,20,68,66,77,90,26};\\n    vector<int> param1 {14,51,10,50,67,25,30,22,1,34};\\n    vector<int> param2 {34,5,24,34,20,40,24,32,71,54};\\n    for(int i = 0; i < param0.size(); ++i)\\n    {\\n        if(f_filled(param0[i],param1[i],param2[i]) == f_gold(param0[i],param1[i],param2[i]))\\n        {\\n            n_success+=1;\\n        }\\n    }\\n    cout << \"#Results:\" << \" \" << n_success << \", \" << param0.size();\\n    return 0;\\n}', 'Translate Java to Python: \\npublic static void main(String args[]) {\\n    int n_success = 0;\\n    List<Integer> param0 = new ArrayList<>();\\n    param0.add(48);\\n    param0.add(11);\\n    param0.add(50);\\n    param0.add(21);\\n    param0.add(94);\\n    param0.add(22);\\n    param0.add(3);\\n    param0.add(67);\\n    param0.add(59);\\n    param0.add(50);\\n    List<Integer> param1 = new ArrayList<>();\\n    param1.add(63);\\n    param1.add(55);\\n    param1.add(89);\\n    param1.add(71);\\n    param1.add(39);\\n    param1.add(44);\\n    param1.add(41);\\n    param1.add(62);\\n    param1.add(2);\\n    param1.add(11);\\n    List<Integer> param2 = new ArrayList<>();\\n    param2.add(56);\\n    param2.add(84);\\n    param2.add(96);\\n    param2.add(74);\\n    param2.add(42);\\n    param2.add(86);\\n    param2.add(68);\\n    param2.add(94);\\n    param2.add(83);\\n    param2.add(1);\\n    for(int i = 0; i < param0.size(); ++i)\\n    {\\n        if(f_filled(param0.get(i),param1.get(i),param2.get(i)) == f_gold(param0.get(i),param1.get(i),param2.get(i)))\\n        {\\n            n_success+=1;\\n        }\\n    }\\n    System.out.println(\"#Results:\" + n_success + \", \" + param0.size());\\n}\\n}', 'Translate Java to Python: \\npublic static void main(String args[]) {\\n    int n_success = 0;\\n    List<Integer> param0 = new ArrayList<>();\\n    param0.add(97);\\n    param0.add(97);\\n    param0.add(32);\\n    param0.add(40);\\n    param0.add(18);\\n    param0.add(14);\\n    param0.add(90);\\n    param0.add(39);\\n    param0.add(1);\\n    param0.add(57);\\n    for(int i = 0; i < param0.size(); ++i)\\n    {\\n        if(f_filled(param0.get(i)) == f_gold(param0.get(i)))\\n        {\\n            n_success+=1;\\n        }\\n    }\\n    System.out.println(\"#Results:\" + n_success + \", \" + param0.size());\\n}\\n}', 'Translate Java to Python: \\nimport java.util. *;\\nimport java.util.stream.*;\\nimport java.lang.*;\\nimport javafx.util.Pair;\\npublic class MODULUS_TWO_FLOAT_DOUBLE_NUMBERS{\\nstatic double f_gold ( double a , double b ) {\\n  if ( a < 0 ) a = - a ;\\n  if ( b < 0 ) b = - b ;\\n  double mod = a ;\\n  while ( mod >= b ) mod = mod - b ;\\n  if ( a < 0 ) return - mod ;\\n  return mod ;\\n}\\n\\n\\n', 'Translate Java to Python: \\nimport java.util. *;\\nimport java.util.stream.*;\\nimport java.lang.*;\\nimport javafx.util.Pair;\\npublic class MINIMUM_INCREMENT_K_OPERATIONS_MAKE_ELEMENTS_EQUAL{\\nstatic int f_gold ( int arr [ ] , int n , int k ) {\\n  Arrays . sort ( arr ) ;\\n  int max = arr [ arr . length - 1 ] ;\\n  int res = 0 ;\\n  for ( int i = 0 ;\\n  i < n ;\\n  i ++ ) {\\n    if ( ( max - arr [ i ] ) % k != 0 ) return - 1 ;\\n    else res += ( max - arr [ i ] ) / k ;\\n  }\\n  return res ;\\n}\\n\\n\\n', 'Translate Python to Java: def f_gold ( string ) :\\n    l = 0\\n    h = len ( string ) - 1\\n    while h > l :\\n        l += 1\\n        h -= 1\\n        if string [ l - 1 ] != string [ h + 1 ] :\\n            return False\\n    return True\\n\\n\\n', 'Translate Python to C++: \\nif __name__ == \\'__main__\\':\\n    param = [\\n    (77,),\\n    (18,),\\n    (83,),\\n    (39,),\\n    (68,),\\n    (28,),\\n    (71,),\\n    (14,),\\n    (21,),\\n    (73,)\\n        ]\\n    n_success = 0\\n    for i, parameters_set in enumerate(param):\\n        if abs(1 - (0.0000001 + abs(f_gold(*parameters_set))) / (abs(f_filled(*parameters_set)) + 0.0000001)) < 0.001:\\n            n_success+=1\\n    print(\"#Results: %i, %i\" % (n_success, len(param)))', 'Translate C++ to Python: \\nusing namespace std;\\nint f_gold ( int n, int m ) {\\n  int count [ n + 1 ];\\n  count [ 0 ] = 0;\\n  for ( int i = 1;\\n  i <= n;\\n  i ++ ) {\\n    if ( i > m ) count [ i ] = count [ i - 1 ] + count [ i - m ];\\n    else if ( i < m ) count [ i ] = 1;\\n    else count [ i ] = 2;\\n  }\\n  return count [ n ];\\n}\\n\\n\\n', 'Translate Python to Java: def f_gold ( mat , N ) :\\n    for row in range ( N ) :\\n        for col in range ( N ) :\\n            if ( row == col and mat [ row ] [ col ] != 1 ) :\\n                return False ;\\n            elif ( row != col and mat [ row ] [ col ] != 0 ) :\\n                return False ;\\n    return True ;\\n\\n\\n', 'Translate Java to C++: \\npublic static void main(String args[]) {\\n    int n_success = 0;\\n    List<Integer> param0 = new ArrayList<>();\\n    param0.add(3);\\n    param0.add(19);\\n    param0.add(39);\\n    param0.add(89);\\n    param0.add(96);\\n    param0.add(68);\\n    param0.add(48);\\n    param0.add(5);\\n    param0.add(3);\\n    param0.add(4);\\n    for(int i = 0; i < param0.size(); ++i)\\n    {\\n        if(f_filled(param0.get(i)) == f_gold(param0.get(i)))\\n        {\\n            n_success+=1;\\n        }\\n    }\\n    System.out.println(\"#Results:\" + n_success + \", \" + param0.size());\\n}\\n}', 'Translate C++ to Java: \\nusing namespace std;\\nint f_gold ( int a, int b, int k ) {\\n  int p = pow ( a, b );\\n  int count = 0;\\n  while ( p > 0 && count < k ) {\\n    int rem = p % 10;\\n    count ++;\\n    if ( count == k ) return rem;\\n    p = p / 10;\\n  }\\n  return 0;\\n}\\n\\n\\n', 'Translate Java to C++: \\nimport java.util. *;\\nimport java.util.stream.*;\\nimport java.lang.*;\\nimport javafx.util.Pair;\\npublic class MINIMUM_ROTATIONS_REQUIRED_GET_STRING{\\nstatic int f_gold ( String str ) {\\n  String tmp = str + str ;\\n  int n = str . length ( ) ;\\n  for ( int i = 1 ;\\n  i <= n ;\\n  i ++ ) {\\n    String substring = tmp . substring ( i , str . length ( ) ) ;\\n    if ( str == substring ) return i ;\\n  }\\n  return n ;\\n}\\n\\n\\n', 'Translate Python to C++: def f_gold ( arr , arr_size ) :\\n    for i in range ( 0 , arr_size ) :\\n        count = 0\\n        for j in range ( 0 , arr_size ) :\\n            if arr [ i ] == arr [ j ] :\\n                count += 1\\n        if ( count % 2 != 0 ) :\\n            return arr [ i ]\\n    return - 1\\n\\n\\n'), ('\\nusing namespace std;\\nstring f_gold ( string s, int n ) {\\n  string s1 = s;\\n  for ( int i = 1;\\n  i < n;\\n  i ++ ) s += s1;\\n  return s;\\n}\\n\\n\\n', '\\nint main() {\\n    int n_success = 0;\\n    vector<float> param0 {2009.019461888707F,-1480.5131394215787F,357.7870347569567F,-8040.293697508038F,3821.882657293133F,-6840.635072240347F,1623.036598830132F,-9714.00706195298F,3916.454769669618F,-669.068424712943F};\\n    for(int i = 0; i < param0.size(); ++i)\\n    {\\n        if(abs(1 - (0.0000001 + abs(f_gold(param0[i])) )/ (abs(f_filled(param0[i])) + 0.0000001)) < 0.001F)\\n        {\\n            n_success+=1;\\n        }\\n    }\\n    cout << \"#Results:\" << \" \" << n_success << \", \" << param0.size();\\n    return 0;\\n}', 'def f_gold ( n ) :\\n    if n < 3 :\\n        return n\\n    elif n >= 3 and n < 10 :\\n        return n - 1\\n    po = 1\\n    while n / po > 9 :\\n        po = po * 10\\n    msd = n / po\\n    if msd != 3 :\\n        return f_gold ( msd ) * f_gold ( po - 1 ) + f_gold ( msd ) + f_gold ( n % po )\\n    else :\\n        return f_gold ( msd * po - 1 )\\n\\n\\n', '\\nif __name__ == \\'__main__\\':\\n    param = [\\n    (19,14,34,),\\n    (23,51,5,),\\n    (92,10,24,),\\n    (9,50,34,),\\n    (20,67,20,),\\n    (68,25,40,),\\n    (66,30,24,),\\n    (77,22,32,),\\n    (90,1,71,),\\n    (26,34,54,)\\n        ]\\n    n_success = 0\\n    for i, parameters_set in enumerate(param):\\n        if f_filled(*parameters_set) == f_gold(*parameters_set):\\n            n_success+=1\\n    print(\"#Results: %i, %i\" % (n_success, len(param)))', '\\nif __name__ == \\'__main__\\':\\n    param = [\\n    (48,63,56,),\\n    (11,55,84,),\\n    (50,89,96,),\\n    (21,71,74,),\\n    (94,39,42,),\\n    (22,44,86,),\\n    (3,41,68,),\\n    (67,62,94,),\\n    (59,2,83,),\\n    (50,11,1,)\\n        ]\\n    n_success = 0\\n    for i, parameters_set in enumerate(param):\\n        if f_filled(*parameters_set) == f_gold(*parameters_set):\\n            n_success+=1\\n    print(\"#Results: %i, %i\" % (n_success, len(param)))', '\\nif __name__ == \\'__main__\\':\\n    param = [\\n    (97,),\\n    (97,),\\n    (32,),\\n    (40,),\\n    (18,),\\n    (14,),\\n    (90,),\\n    (39,),\\n    (1,),\\n    (57,)\\n        ]\\n    n_success = 0\\n    for i, parameters_set in enumerate(param):\\n        if f_filled(*parameters_set) == f_gold(*parameters_set):\\n            n_success+=1\\n    print(\"#Results: %i, %i\" % (n_success, len(param)))', 'def f_gold ( a , b ) :\\n    if ( a < 0 ) :\\n        a = - a\\n    if ( b < 0 ) :\\n        b = - b\\n    mod = a\\n    while ( mod >= b ) :\\n        mod = mod - b\\n    if ( a < 0 ) :\\n        return - mod\\n    return mod\\n\\n\\n', 'def f_gold ( arr , n , k ) :\\n    max1 = max ( arr )\\n    res = 0\\n    for i in range ( 0 , n ) :\\n        if ( ( max1 - arr [ i ] ) % k != 0 ) :\\n            return - 1\\n        else :\\n            res += ( max1 - arr [ i ] ) / k\\n    return int ( res )\\n\\n\\n', '\\nimport java.util. *;\\nimport java.util.stream.*;\\nimport java.lang.*;\\nimport javafx.util.Pair;\\npublic class CHECK_GIVEN_STRING_ROTATION_PALINDROME{\\nstatic boolean f_gold ( String str ) {\\n  int l = 0 ;\\n  int h = str . length ( ) - 1 ;\\n  while ( h > l ) if ( str . charAt ( l ++ ) != str . charAt ( h -- ) ) return false ;\\n  return true ;\\n}\\n\\n\\n', '\\nint main() {\\n    int n_success = 0;\\n    vector<int> param0 {77,18,83,39,68,28,71,14,21,73};\\n    for(int i = 0; i < param0.size(); ++i)\\n    {\\n        if(abs(1 - (0.0000001 + abs(f_gold(param0[i])) )/ (abs(f_filled(param0[i])) + 0.0000001)) < 0.001F)\\n        {\\n            n_success+=1;\\n        }\\n    }\\n    cout << \"#Results:\" << \" \" << n_success << \", \" << param0.size();\\n    return 0;\\n}', 'def f_gold ( n , m ) :\\n    count = [ ]\\n    for i in range ( n + 2 ) :\\n        count.append ( 0 )\\n    count [ 0 ] = 0\\n    for i in range ( 1 , n + 1 ) :\\n        if ( i > m ) :\\n            count [ i ] = count [ i - 1 ] + count [ i - m ]\\n        elif ( i < m ) :\\n            count [ i ] = 1\\n        else :\\n            count [ i ] = 2\\n    return count [ n ]\\n\\n\\n', '\\nimport java.util. *;\\nimport java.util.stream.*;\\nimport java.lang.*;\\nimport javafx.util.Pair;\\npublic class PROGRAM_PRINT_IDENTITY_MATRIX_1{\\nstatic boolean f_gold ( int mat [ ] [ ] , int N ) {\\n  for ( int row = 0 ;\\n  row < N ;\\n  row ++ ) {\\n    for ( int col = 0 ;\\n    col < N ;\\n    col ++ ) {\\n      if ( row == col && mat [ row ] [ col ] != 1 ) return false ;\\n      else if ( row != col && mat [ row ] [ col ] != 0 ) return false ;\\n    }\\n  }\\n  return true ;\\n}\\n\\n\\n', '\\nint main() {\\n    int n_success = 0;\\n    vector<int> param0 {3,19,39,89,96,68,48,5,3,4};\\n    for(int i = 0; i < param0.size(); ++i)\\n    {\\n        if(f_filled(param0[i]) == f_gold(param0[i]))\\n        {\\n            n_success+=1;\\n        }\\n    }\\n    cout << \"#Results:\" << \" \" << n_success << \", \" << param0.size();\\n    return 0;\\n}', '\\nimport java.util. *;\\nimport java.util.stream.*;\\nimport java.lang.*;\\nimport javafx.util.Pair;\\npublic class K_TH_DIGIT_RAISED_POWER_B{\\npublic static int f_gold ( int a , int b , int k ) {\\n  int p = ( int ) Math . pow ( a , b ) ;\\n  int count = 0 ;\\n  while ( p > 0 && count < k ) {\\n    int rem = p % 10 ;\\n    count ++ ;\\n    if ( count == k ) return rem ;\\n    p = p / 10 ;\\n  }\\n  return 0 ;\\n}\\n\\n\\n', '\\nusing namespace std;\\nint f_gold ( string str ) {\\n  string tmp = str + str;\\n  int n = str . length ( );\\n  for ( int i = 1;\\n  i <= n;\\n  i ++ ) {\\n    string substring = tmp . substr ( i, str . size ( ) );\\n    if ( str == substring ) return i;\\n  }\\n  return n;\\n}\\n\\n\\n', '\\nusing namespace std;\\nint f_gold ( int arr [ ], int arr_size ) {\\n  for ( int i = 0;\\n  i < arr_size;\\n  i ++ ) {\\n    int count = 0;\\n    for ( int j = 0;\\n    j < arr_size;\\n    j ++ ) {\\n      if ( arr [ i ] == arr [ j ] ) count ++;\\n    }\\n    if ( count % 2 != 0 ) return arr [ i ];\\n  }\\n  return - 1;\\n}\\n\\n\\n')]\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataloader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To forward pass\n",
      "To loss\n",
      "To backward pass\n",
      "Updating learning rate\n",
      "To forward pass\n",
      "To loss\n",
      "To backward pass\n",
      "Updating learning rate\n",
      "To forward pass\n",
      "To loss\n",
      "To backward pass\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Langchain\\Code Migration\\FineTuning.ipynb Cell 10\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Langchain/Code%20Migration/FineTuning.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTo backward pass\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Langchain/Code%20Migration/FineTuning.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Langchain/Code%20Migration/FineTuning.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Langchain/Code%20Migration/FineTuning.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Langchain/Code%20Migration/FineTuning.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Update the learning rate\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "for epoch in range(2000):\n",
    "    for batch in train_dataloader:\n",
    "        input_text = \"\"\n",
    "        for snippet_tuple in batch:\n",
    "            input_text += snippet_tuple[0] + \"\\n\" + snippet_tuple[1] + \"\\n\"\n",
    "        # Convert the list of code snippets to tensors\n",
    "        batch = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "        # Move the batch to the GPU\n",
    "        batch = batch.to(accelerator.device)\n",
    "        print(\"To forward pass\")\n",
    "        # Forward pass\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        # Loss\n",
    "        print(\"To loss\")\n",
    "        loss = torch.mean(outputs[0])  # Compute the average loss across the batch.\n",
    "\n",
    "        # Backward pass\n",
    "        print(\"To backward pass\")\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate\n",
    "        print(\"Updating learning rate\")\n",
    "        scheduler.step()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"fine-tuned-bart-base-code-migration\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
